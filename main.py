# -*- coding: utf-8 -*-
"""implementation_pcb_v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sN3xrtheple_75ereZgIAPHiPKVpTucL
"""

# mounting to gdrive
from google.colab import drive
drive.mount('/content/gdrive')

# !pip install -U --pre tensorflow=="2.*"
# !pip install tf_slim
# !pip install pycocotools

# Commented out IPython magic to ensure Python compatibility.
# %cd gdrive/My Drive/project_TA/

import os
from pathlib import Path

if Path('v3').is_dir():
  print("folder already exist!")
else:
  !mkdir v3

# Commented out IPython magic to ensure Python compatibility.
# %cd v3

if Path('models').is_dir():
  print("folder already exist!")
else:
  !git clone --depth 1 https://github.com/tensorflow/models

# Commented out IPython magic to ensure Python compatibility.
# %cd models/research/

!protoc object_detection/protos/*.proto --python_out=.
!wget https://raw.githubusercontent.com/asyml/texar/master/setup.py

"""**replace this code to ../models/research/setup.py**


```python
...
    install_requires=[
        'regex',
        'numpy',
        'pathlib',
        'pyyaml',
        'requests',
        'funcsigs',
        'sentencepiece',
        'packaging'
    ],
    extras_require={
        'tensorflow-cpu': [
            'tensorflow>=1.10.0,<2.0',
            'tensorflow-probability>=0.3.0,<0.8.0'
        ],
        'tensorflow-gpu': [
            'tensorflow-gpu>=1.10.0,<2.0',
            'tensorflow-probability>=0.3.0,<0.8.0'
        ]
    },
    package_data={
        "texar": [
            "../bin/utils/multi-bleu.perl",
        ]
    },
    classifiers=[
        'Intended Audience :: Developers',
        'Intended Audience :: Education',
        'Intended Audience :: Science/Research',
        'Operating System :: OS Independent',
        'Programming Language :: Python',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
    ],
...
```


"""

!pip install .

if Path('use_protobuf.py').is_file():
  print ("file already exist!")
else:
  !touch use_protobuf.py
  !python use_protobuf.py object_detection/protos protoc

"""**Copy this code into use_protobuf.py**



```python
import os
import sys
args = sys.argv
directory = args[1]
protoc_path = args[2]
for file in os.listdir(directory):
    if file.endswith(".proto"):
        os.system(protoc_path+" "+directory+"/"+file+" --python_out=.")
```
"""

!pip install google-cloud-storage
!pip install google-cloud-pubsub
!pip install google-cloud-bigquery
!pip install apache-beam

"""**Just ignore if you see errors when run code above**"""

# Commented out IPython magic to ensure Python compatibility.
# # Install TensorFlow Object Detection API.
# %%bash 
# cp object_detection/packages/tf2/setup.py .
# pip install .

!python object_detection/builders/model_builder_tf2_test.py

"""**Setup environment is finished**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd object_detection/

if Path('images').is_dir():
  print("folder already exist!")
else:
  !mkdir images

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd images
# cp -R /content/gdrive/MyDrive/project_TA/dataset/train .
# cp -R /content/gdrive/MyDrive/project_TA/dataset/test .

if Path('xml_to_csv.py').is_file():
  print ("file already exist!")
else:
  !touch xml_to_csv.py
  !python xml_to_csv.py

"""**Copy paste this code to xml_to_csv.py**

```python
# based on https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py

import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df


def main():
    for folder in ['train', 'test']:
        image_path = os.path.join(os.getcwd(), ('images/' + folder))
        xml_df = xml_to_csv(image_path)
        xml_df.to_csv(('images/'+folder+'_labels.csv'), index=None)
    print('Successfully converted xml to csv.')


main()
```


"""

!python xml_to_csv.py

if Path('generate_tfrecord.py').is_file():
  print ("file already exist!")
else:
  !touch generate_tfrecord.py
  !python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record
  !python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record

"""**Copy paste this code to generate_tfrecord.py**



```python
#based on https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py

from __future__ import division
from __future__ import print_function
from __future__ import absolute_import

import os
import io
import pandas as pd

from tensorflow.python.framework.versions import VERSION
if VERSION >= "2.0.0a0":
    import tensorflow.compat.v1 as tf
else:
    import tensorflow as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

flags = tf.app.flags
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
flags.DEFINE_string('image_dir', '', 'Path to images')
FLAGS = flags.FLAGS


def class_text_to_int(row_label):
    if row_label == 'burnout':
        return 1
    else:
        return None


def split(df, group):
    data = namedtuple('data', ['filename', 'object'])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(FLAGS.image_dir)
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, 'filename')
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print('Successfully created the TFRecords: {}'.format(output_path))


if __name__ == '__main__':
    tf.app.run()
```


"""

!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record
!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record

if Path('training').is_dir():
  print("folder already exist!")
else:
  !mkdir training

# Commented out IPython magic to ensure Python compatibility.
# %cd training/

if Path('label_map.pbtxt').is_file():
  print ("file already exist!")
else:
  !touch label_map.pbtxt

"""**copy paste to label_map.pbtxt**



```python
item {
    id: 1
    name: 'burnout'
}
```
"""

!cp ../configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config .

import requests
file_url = "http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz"
	
r = requests.get(file_url, stream = True)

with open("/content/gdrive/My Drive/project_TA/efficientdet_d0_coco17_tpu-32.tar.gz", "wb") as file:
	for block in r.iter_content(chunk_size = 1024):
		if block:
			file.write(block)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/project_TA/

!tar xvzf efficientdet_d0_coco17_tpu-32.tar.gz

!cp -R efficientdet_d0_coco17_tpu-32 v3/models/research/object_detection/

"""**Configuring SSD architecture**



```config
# SSD with EfficientNet-b0 + BiFPN feature extractor,
# shared box predictor and focal loss (a.k.a EfficientDet-d0).
# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070
# See Lin et al, https://arxiv.org/abs/1708.02002
# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.
#
# Train on TPU-8

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 1
    add_background_class: false
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 3
      }
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 512
        max_dimension: 512
        pad_to_max_dimension: true
        }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 64
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          force_use_bias: true
          activation: SWISH
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true
            decay: 0.99
            epsilon: 0.001
          }
        }
        num_layers_before_predictor: 3
        kernel_size: 3
        use_depthwise: true
      }
    }
    feature_extractor {
      type: 'ssd_efficientnet-b0_bifpn_keras'
      bifpn {
        min_level: 3
        max_level: 7
        num_iterations: 3
        num_filters: 64
      }
      conv_hyperparams {
        force_use_bias: true
        activation: SWISH
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.99,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 1.5
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.5
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint: "/content/gdrive/MyDrive/project_TA/v1/models/research/object_detection/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0"
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint_type: "detection"
  batch_size: 16
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  use_bfloat16: true
  num_steps: 300000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_scale_crop_and_pad_to_square {
      output_size: 512
      scale_min: 0.1
      scale_max: 2.0
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 8e-2
          total_steps: 300000
          warmup_learning_rate: .001
          warmup_steps: 2500
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  label_map_path: "/content/gdrive/MyDrive/project_TA/v1/models/research/object_detection/training/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "/content/gdrive/MyDrive/project_TA/v1/models/research/object_detection/train.record"
  }
}

eval_config: {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  label_map_path: "/content/gdrive/MyDrive/project_TA/v1/models/research/object_detection/training/label_map.pbtxt"
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: "/content/gdrive/MyDrive/project_TA/v1/models/research/object_detection/test.record"
  }
}
```


"""

# Commented out IPython magic to ensure Python compatibility.
# %cd v3/models/research/object_detection

!python model_main_tf2.py \
    --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config \
    --model_dir=training \
    --alsologtostderr

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir=training/train

!python exporter_main_v2.py \
    --trained_checkpoint_dir=training \
    --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config \
    --output_directory inference_graph

# from google.protobuf import text_format

# with open('graph.pbtxt') as f:
#     text_graph = f.read()
# graph_def = text_format.Parse(text_graph, tf.GraphDef())
# tf.train.write_graph(graph_def, path, 'graph.pb', as_text=False)

# from google.colab import files
# files.download(f'/content/{output_directory}/saved_model/saved_model.pb')

"""**Test the model**"""

# Commented out IPython magic to ensure Python compatibility.
import io
import os
import scipy.misc
import numpy as np
import six
import time
import glob
from IPython.display import display

from six import BytesIO

import matplotlib
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont

import tensorflow as tf
from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

# %matplotlib inline

def load_image_into_numpy_array(path):
  """Load an image from file into a numpy array.

  Puts image into numpy array to feed into tensorflow graph.
  Note that by convention we put it into a numpy array with shape
  (height, width, channels), where channels=3 for RGB.

  Args:
    path: a file path (this can be local or on colossus)

  Returns:
    uint8 numpy array with shape (img_height, img_width, 3)
  """
  img_data = tf.io.gfile.GFile(path, 'rb').read()
  image = Image.open(BytesIO(img_data))
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

labelmap_path = '/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/training/label_map.pbtxt'

category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)

tf.keras.backend.clear_session()
model = tf.saved_model.load(f'/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model')

def run_inference_for_single_image(model, image):
  image = np.asarray(image)
  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
  input_tensor = tf.convert_to_tensor(image)
  # The model expects a batch of images, so add an axis with `tf.newaxis`.
  input_tensor = input_tensor[tf.newaxis,...]

  # Run inference
  model_fn = model.signatures['serving_default']
  output_dict = model_fn(input_tensor)

  # All outputs are batches tensors.
  # Convert to numpy arrays, and take index [0] to remove the batch dimension.
  # We're only interested in the first num_detections.
  num_detections = int(output_dict.pop('num_detections'))
  output_dict = {key:value[0, :num_detections].numpy() 
                 for key,value in output_dict.items()}
  output_dict['num_detections'] = num_detections

  # detection_classes should be ints.
  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
   
  # Handle models with masks:
  if 'detection_masks' in output_dict:
    # Reframe the the bbox mask to the image size.
    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
              output_dict['detection_masks'], output_dict['detection_boxes'],
               image.shape[0], image.shape[1])      
    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,
                                       tf.uint8)
    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()
    
  return output_dict

for image_path in glob.glob('/content/gdrive/MyDrive/project_TA/dataset/test/*.jpg'):
  image_np = load_image_into_numpy_array(image_path)
  output_dict = run_inference_for_single_image(model, image_np)
  vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks_reframed', None),
      use_normalized_coordinates=True,
      line_thickness=8)
  display(Image.fromarray(image_np))

# import os
# import tensorflow as tf
# from tensorflow.keras.preprocessing import image

# New_Model = tf.keras.models.load_model('/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model') # Loading the Tensorflow Saved Model (PB)
# print(New_Model.summary())

# # Saving the Model in H5 Format and Loading it (to check if it is same as PB Format)
# tf.keras.models.save_model(New_Model, 'New_Model.h5') # Saving the Model in H5 Format

# loaded_model_from_h5 = tf.keras.models.load_model('New_Model.h5') # Loading the H5 Saved Model
# print(loaded_model_from_h5.summary())

"""**Converting model to web format**"""

!pip install tensorflowjs

import os
from pathlib import Path

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    --output_node_names='EfficientdetD0/Predictions/Reshape_1' \
    --saved_model_tags=serve \
    /content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model \
    /content/gdrive/MyDrive/project_TA/web_format

import argparse, os, pathlib, sys
import tensorflow as tf
from google.protobuf import text_format
from tensorflow.python.platform import gfile


def pbtxt_to_graphdef(filename):
  print("\n[CONVERT] Converting from .pbtxt to .pb: '{}'\n".format(filename))
  with open(filename, 'r') as f:
    graph_def = tf.compat.v1.GraphDef()
    file_content = f.read()
    text_format.Merge(file_content, graph_def)
    tf.import_graph_def(graph_def, name='')
    in_dir = os.path.dirname(filename)
    out_filename = os.path.splitext(os.path.basename(filename))[0] + ".pb"
    tf.io.write_graph(graph_def, in_dir, out_filename, as_text=False)
  print("\n[CONVERT] Wrote file to: '{}'\n".format(os.path.join(in_dir, out_filename)))


with tf.Session() as sess:
    model_filename ='/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model/saved_model.pb'
    with gfile.FastGFile(model_filename, 'rb') as f:
        data = compat.as_bytes(f.read())
        sm = saved_model_pb2.SavedModel()
        sm.ParseFromString(data)
        g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)
        in_dir = os.path.dirname(model_filename)
        out_filename = os.path.splitext(os.path.basename(model_filename))[0] + ".pbtxt"
        tf.io.write_graph(g_in, in_dir, out_filename, as_text=True)
    print("\n[CONVERT] Wrote file to: '{}'\n".format(os.path.join(in_dir, out_filename)))


def graphdef_to_pbtxt(filename):
  print("\n[CONVERT] Converting from .pb to .pbtxt: '{}'\n".format(filename))
  with gfile.FastGFile(filename, 'rb') as f:
      graph_def = tf.compat.v1.GraphDef()
      graph_def.ParseFromString(f.read())
      tf.import_graph_def(graph_def, name='')
      in_dir = os.path.dirname(filename)
      out_filename = os.path.splitext(os.path.basename(filename))[0] + ".pbtxt"
      tf.io.write_graph(graph_def, in_dir, out_filename, as_text=True)
  print("\n[CONVERT] Wrote file to: '{}'\n".format(os.path.join(in_dir, out_filename)))

graphdef_to_pbtxt('/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model/saved_model.pb')

import tensorflow.compat.v1 as tf
import sys
from tensorflow.python.platform import gfile
from tensorflow.core.protobuf import saved_model_pb2
from tensorflow.python.util import compat

with tf.Session() as sess:
    model_filename ='/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model/saved_model.pb'
    with gfile.FastGFile(model_filename, 'rb') as f:
        data = compat.as_bytes(f.read())
        sm = saved_model_pb2.SavedModel()
        sm.ParseFromString(data)
        g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)

import tensorflow.compat.v1 as tf
import sys
from tensorflow.python.platform import gfile
from tensorflow.core.protobuf import saved_model_pb2
from tensorflow.python.util import compat

with tf.Session() as sess:
    model_filename ='/content/gdrive/MyDrive/project_TA/v3/models/research/object_detection/inference_graph/saved_model/saved_model.pb'
    with gfile.FastGFile(model_filename, 'rb') as f:
        data = compat.as_bytes(f.read())
        sm = saved_model_pb2.SavedModel()
        sm.ParseFromString(data)
        g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)
        in_dir = os.path.dirname(model_filename)
        out_filename = os.path.splitext(os.path.basename(model_filename))[0] + ".pbtxt"
        tf.io.write_graph(sm, in_dir, out_filename, as_text=True)
    print("\n[CONVERT] Wrote file to: '{}'\n".format(os.path.join(in_dir, out_filename)))
